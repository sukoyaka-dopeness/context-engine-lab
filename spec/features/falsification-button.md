# Feature Spec: Falsification Button

## Purpose

Shift the user's cognitive mode from *accusation* to *inquiry*.  
The question is not "Is this wrong?" but "What would make this testable?"

This is the Popperian move made accessible.

---

## Label

> *"What would it take to falsify this?"*

---

## Behavior

1. User clicks the Falsification Button on any claim
2. System generates a hypothetical prediction:  
   *"If this claim is true, we would expect to observe X. If false, we would expect to observe Y."*
3. Output displayed with mandatory uncertainty disclosure:
   > *"This is a hypothetical prediction generated by AI. It may be incomplete or incorrect. Primary sources and domain expertise should be consulted."*
4. Link displayed below output:  
   *"Want to test this? → [Post to Open Lab]"*

---

## Output Requirements

- Must specify what evidence would **support** the claim
- Must specify what evidence would **falsify** the claim
- Must acknowledge if the claim is structured to resist falsification
- Uncertainty disclosure is non-optional and cannot be removed by any user or operator setting

---

## Edge Cases

### Unfalsifiable claims
If `claim_type` is `conspiratorial` or the claim is structured to absorb all counter-evidence:

> *"This claim is structured in a way that makes falsification difficult to define. Claims that cannot in principle be falsified cannot be confirmed by evidence either. See: Popper, falsifiability."*

### Normative claims
If `claim_type` is `normative`:

> *"This is a normative claim — about what should be, not what is. Falsification applies to empirical predictions, not value statements. The relevant question here is: what values and evidence is this claim built on?"*

### Hybrid claims
If `secondary_layer` is present in the tag:

> *"This claim has both empirical and [secondary_layer] dimensions. The falsification prompt below addresses the empirical layer. The [secondary_layer] dimension involves questions that evidence alone cannot resolve."*

---

## Open Lab Link

Displayed below every Falsification Button output.

**Target:** OSF (Open Science Framework), Zenodo, or project-internal mini-version (MVP).

**Entry form (low-cost, 5 fields maximum):**

| Field | Type |
|-------|------|
| Claim being tested | Pre-filled from button context |
| Method used | Free text |
| Result | Free text |
| Source or link | Optional |
| Notes | Optional |

Submitting to Open Lab triggers `Verification_Attempted` badge consideration.  
If a source is included, `Primary_Source_Added` badge consideration is also triggered.

---

## Relationship to Other Features

| Feature | Relationship |
|---------|-------------|
| Tag System | `claim_type` tag determines which edge case handling applies |
| Forewarning Box | Falsification prompt reinforces forewarning on false-balance topics |
| Badge System | Open Lab submission triggers badge consideration |
| AI Non-Authority Principle | Uncertainty disclosure on output is a direct application |
