# Success Criteria

## Philosophy

Epistemic literacy manifests behaviorally, not declaratively.  
We do not measure whether users *say* they are more open-minded.  
We measure what they *do*.

Metrics exist to enable observation and iteration.  
They do not exist to be optimized against.  
If any metric becomes a primary objective rather than an indicator, it should be revised or removed.

---

## Behavioral Indicators

| Indicator | What it measures | Collection method |
|-----------|-----------------|------------------|
| User-generated tag count | Engagement with structural annotation | Platform analytics |
| Primary source click rate | Movement toward primary evidence | Link analytics |
| Aggression frequency trend | Reduction in escalatory rhetoric over time | Rhetoric-style tag accumulation rate |
| Replication links posted | Embodied scientific method adoption | Open Lab submissions |
| Belief update records created | Normalization of belief revision | Personal record log trigger rate |
| Research history timeline usage | Engagement with scientific tentativeness | Section view analytics |
| Falsification button usage | Shift from accusation to inquiry | Feature analytics |
| Meta-layer acceptance rate | Willingness to examine impasse structure | UI interaction logs |
| Context package open rate | Engagement with task context provision | Task interface analytics |
| AI error corrections submitted | Embodied AI non-authority principle | Issue tracker, label: ai-error |

---

## Minimum Viable Success

### Phase 1 → Phase 2 transition threshold

| Condition | Threshold |
|-----------|-----------|
| Topics published with AI-generated content | ≥ 20 |
| Topics with at least one human-verified correction | ≥ 5 |
| Inbound links from live SNS discussions | ≥ 1 |

**Rationale:**  
The chicken-and-egg problem (U1) requires demonstrable content before inflow strategy can activate. These conditions are the minimum necessary for Phase 2 to be attempted without the platform appearing empty to arriving users.

### Phase 2 → Phase 3 transition threshold

| Condition | Threshold |
|-----------|-----------|
| Sustained non-zero inbound traffic from SNS links | Demonstrated over ≥ 4 weeks |
| User-generated tags from non-founding contributors | Any |
| Falsification button usage | Any non-zero rate |

**Rationale:**  
Phase 3 activates the participation layer. Attempting Phase 3 before Phase 2 demonstrates stable inflow risks building participation infrastructure for an audience that does not yet exist.

---

## Long-Term Indicators

**Existence durability**  
Does the platform persist over time? An epistemic literacy project that disappears validates cynicism about the enterprise. Longevity is itself a success criterion.

**Replication culture**  
Are users posting experiment attempts to Open Lab? This is the highest behavioral signal — it indicates that the scientific method has been adopted as a practice, not just acknowledged as a concept.

**Aggression reduction**  
Is Cool-Down rate limiting correlated with reduced escalation? Correlation is expected and measurable. Causation requires more careful analysis — confounders include topic selection, user self-selection, and platform growth stage.

**Self-classification rate**  
Do users tag their own epistemic positions? This is the most demanding behavior change this platform asks for. Low initial rates are expected. Trend direction over time is the meaningful signal.

**Belief update record rate**  
Are users creating `Belief_Updated` records? The absolute number matters less than whether the rate is nonzero and whether it is treated as normal rather than exceptional by the community.

---

## What We Are Not Measuring

- Whether users agree with scientific consensus
- Whether users change their political positions
- Whether correct beliefs increase in frequency
- Whether the platform wins arguments

These would transform this into a covert persuasion project.  
The goal is epistemic method literacy — how beliefs are formed and tested — not belief content correction.

---

## Metric Design Limits

> *"Observation enables iteration. Avoid metric tyranny."*

All metrics can be gamed.  
All metrics simplify.  
Quantification is minimal but present — enough to observe, not enough to optimize against.

**Goodhart's Law applies:**  
When a measure becomes a target, it ceases to be a good measure.  
This applies to every metric listed in this document, including the phase transition thresholds.

If evidence emerges that a metric is being optimized against rather than used as an indicator, the appropriate response is to revise or remove the metric — not to defend it because it was previously agreed upon.

See [`docs/unresolved-issues.md`](../docs/unresolved-issues.md) — U9 (weaponization risk applies to metrics as well as content).
